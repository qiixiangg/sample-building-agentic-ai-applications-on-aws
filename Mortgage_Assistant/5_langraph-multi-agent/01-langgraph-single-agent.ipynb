{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d8af4d",
   "metadata": {},
   "source": [
    "# Building a Single Agent  - with LangGraph\n",
    "\n",
    "## Table of contents\n",
    "- [Introduction](#introduction)\n",
    "- [Prerequisites](#prerequisites)\n",
    "- [Create Single Agent](#setup)\n",
    "- [Summary](#summary)\n",
    "\n",
    "## Introduction\n",
    "**LangGraph** is an extension of LangChain that provides a framework for building stateful agent applications. This notebook demonstrates how to create a mortgage assistant using LangGraph that can help customers access information about their existing mortgages.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand how to create a single agent using LangGraph\n",
    "2. Learn how to define tools for retrieving mortgage information\n",
    "3. Implement the ReAct pattern for reasoning and action execution\n",
    "4. Build a simple conversational interface for mortgage assistance\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this notebook, ensure you have:\n",
    "- Familiarity with LangChain concepts (optional but helpful)\n",
    "- Basic understanding of Python and Jupyter notebooks\n",
    "- AWS account with access to Amazon Bedrock and SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc1339d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Start by installing some of the required packages, including LangChain for pre-built tool components, LangGraph for agent workflows, and other necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall boto3 botocore awscli --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d969923",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a418c6d6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important:</b> restart the kernel before proceeding with the next cells. You can use the restart icon on the top of this notebook or  uncomment below cell and execute\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d532ab",
   "metadata": {},
   "source": [
    "Import the following modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c001fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated, Union\n",
    "from langchain_aws import ChatBedrock, ChatBedrockConverse\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent, ToolNode,tools_condition\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, AnyMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from IPython.display import display,Image\n",
    "import random\n",
    "from textwrap import dedent\n",
    "from langchain.tools import tool\n",
    "from datetime import datetime, timedelta\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc393c",
   "metadata": {},
   "source": [
    "\n",
    "Next, we setup the LLMs to be used for this lab. Although you will use these specific models for this lab, LangChain also supports models from other [providers](https://python.langchain.com/docs/integrations/chat/#featured-providers)\n",
    "\n",
    "\n",
    "When setting up an LLM model, you can also set model parameters. In this case, we set `temperature` to 0.7 to balance creativity with accuracy. A higher temperature (closer to 1.0) would produce more creative but potentially less accurate responses, while a lower temperature (closer to 0) would produce more deterministic responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ceee9",
   "metadata": {},
   "source": [
    "If you're running this notebook locally, set the AWS_PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['AWS_PROFILE']='stcgenai'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a734c",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Create Your First Agent\n",
    "\n",
    "Let's start by creating the first agent - the existing mortgage agent. This agent will be responsible for gathering existing loan information for the customer\n",
    "\n",
    "\n",
    "\n",
    "### Understanding LangGraph\n",
    "\n",
    "LangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\n",
    "\n",
    "LangGraph uses the concept of `StateGraph`, an object that defines the structure as state machine. The Graph has `nodes` and edges :\n",
    "-  a node can be an LLM or tool/function \n",
    "-  en edge is how you specify the nodes are connected and state is transitioned along the graph\n",
    "\n",
    "\n",
    "First step in creating a graph is to define the state which includes the graph's schema and reducer functions that handle state updates\n",
    "\n",
    "LangGraph has pre-built `MessageState` that can be imported directly. If you have complex schemas, you can define them accordingly. For this lab, we will use the pre-built State schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(MessagesState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734da45e",
   "metadata": {},
   "source": [
    "Next, we shall define a `get_mortgage_details` function which will be used as a tool for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dab586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_mortgage_details(customer_id: str) -> str:\n",
    "    \"\"\"\n",
    "Retrieves the details about an application for a new mortgage.\n",
    "The function takes a customer ID, but it is purely optional. The function\n",
    "implementation can retrieve it from session state instead. Details include\n",
    "the application ID, application date, application status, application type,\n",
    "application amount, mortgage interest, and application term in years\"\"\"\n",
    "    return {\n",
    "        \"account_number\": customer_id,\n",
    "        \"outstanding_principal\": 150599.25,\n",
    "        \"interest_rate\": 8.5,\n",
    "        \"maturity_date\": \"2030-06-30\",\n",
    "        \"original_issue_date\": \"2021-05-30\",\n",
    "        \"payments_remaining\": 72,\n",
    "        \"last_payment_date\": str(datetime.today() - timedelta(days=14)).split(' ')[0],\n",
    "        \"next_payment_due\": str(datetime.today() + timedelta(days=14)).split(' ')[0],\n",
    "        \"next_payment_amount\": 1579.63\n",
    "    }\n",
    "\n",
    "def create_customer_id():\n",
    "\n",
    "    \"\"\"\n",
    "    Creates customer ID\"\"\"\n",
    "    return \"123456\"\n",
    "\n",
    "def create_loan_application(customer_id, name, age, annual_income, annual_expense):\n",
    "    \"\"\"Creates a new loan application using the details provided. The details include the name,\n",
    "            age, customer_id, annual_income and annual_expense\n",
    "            \"\"\"\n",
    "    print(f\"creating loan application for customer: {customer_id}...\")\n",
    "    print(f\"customer name: {name}\")\n",
    "    print(f\"customer age: {age}\")\n",
    "    print(f\"customer annual income: {annual_income}\")\n",
    "    print(f\"customer annual expense: {annual_expense}\")\n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"customer_name\": name,\n",
    "        \"age\": age,\n",
    "        \"annual_income\": annual_income,\n",
    "        \"annual_expense\": annual_expense,\n",
    "        \"application_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"message\": \"Loan application successfully created\"\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "def get_mortgage_app_doc_status(customer_id):\n",
    "    \"\"\"Retrieves the list of required documents for a mortgage application in process, \n",
    "along with their respective statuses (COMPLETED or MISSING). \n",
    "The function takes a customer ID, but it is purely optional. The funciton\n",
    "implementation can retrieve it from session state instead.\n",
    "This function returns a list of objects, where each object represents \n",
    "a required document type. \n",
    "The required document types for a mortgage application are: proof of income, employment information, \n",
    "proof of assets, and credit information. Each object in the returned list contains the type of the \n",
    "required document and its corresponding status.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"type\": \"proof_of_income\",\n",
    "            \"status\": \"COMPLETED\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"employment_information\",\n",
    "            \"status\": \"MISSING\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"proof_of_assets\",\n",
    "            \"status\": \"COMPLETED\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"credit_information\",\n",
    "            \"status\": \"COMPLETED\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f8dbb",
   "metadata": {},
   "source": [
    "Once the tool function is defined, we move on to setting up the model. LangGraph uses [init_chat_model()](https://python.langchain.com/docs/how_to/chat_models_universal_init/) helper method to make it easy to initialise different models via respective model providers. \n",
    "\n",
    "For the lab, we will use models provided via  Amazon Bedrock. \n",
    "\n",
    "Depending on the model availability and the region  you are running this lab, change the agent_foundation_model[] and region_name before instantiating the boto client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59338653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_foundation_model = [\n",
    "    'us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "    ]\n",
    "\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name='us-east-1')\n",
    "\n",
    "print(f\"Client region:{bedrock_client.meta.region_name}\")\n",
    "\n",
    "model = init_chat_model(\n",
    "    agent_foundation_model[0],\n",
    "    model_provider=\"bedrock_converse\",\n",
    "    temperature=0.7,\n",
    "    client=bedrock_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faec1b5",
   "metadata": {},
   "source": [
    "LangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, reusable components designed to help you construct agentic systems quickly and reliablyâ€”without the need to implement `orchestration, memory, or human feedback handling from scratch`\n",
    "\n",
    "If we were to build using low-level primitives, firstly you define a node, initiate the graph, add nodes and compile the graph:\n",
    "\n",
    "```# Define the Node\n",
    "def existing_mortgage_node(state: AgentState):\n",
    "    # Define the Node\n",
    "    existing_mortgage_node = existing_mortgage_agent.invoke(state)\n",
    "    return existing_mortgage_node\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"existing_mortgage_agent\", existing_mortgage_node)\n",
    "graph.add_edge(START,\"existing_mortgage_agent\")\n",
    "graph.add_edge(\"existing_mortgage_agent\",END)\n",
    "\n",
    "app = graph.compile()\n",
    "```\n",
    "\n",
    "The [create_react_agent](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent) is a high level pre-built component that takes care of this and returns a compiled graph, so we wont need to define the graph, add nodes, and returns the compiled graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ed45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent\n",
    "system =         \"\"\"\n",
    "    You are a mortgage bot for creating, managing, and completing an application for a new mortgage. you greet the customer before your answer.\n",
    "You first ask customers for their customer id. If they don't have any then you use the tool to create a new customer id and tell the user that you have created a new customer id and show it to them.\n",
    "Next, you ask for their name, age, annual income and annual expense. Ask one question at a time. If they cant answer any of the questions then its fine, you just move forward. \n",
    "Once you have all the information use the tool to create a new loan application for this customer. \n",
    "After creating the loan application give the customer their newly created customer id if they didn't provide one initially.\n",
    "never make up information that you are unable to retrieve from your available actions. \n",
    "do not engage with users about topics other than an existing mortgage. leave those other topics for other experts to handle. for example, do not respond to general questions about mortgages. However, respond to the greeting by another greeting\n",
    " \"\"\"\n",
    "existing_mortgage_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_mortgage_details,create_customer_id,create_loan_application,get_mortgage_app_doc_status],\n",
    "    prompt=dedent(system)\n",
    "\n",
    ")\n",
    "\n",
    "#visualise the graph\n",
    "display(Image(existing_mortgage_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5ed76",
   "metadata": {},
   "source": [
    "Once the agent is created, we can interact with the agent using `invoke()` or `stream()`. For this lab, we shall use invoke(). For additional methods available for the graph, you can read [here](https://langchain-ai.github.io/langgraph/reference/graphs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = existing_mortgage_agent.invoke(\n",
    "    {\"messages\": \"Howdy\"})\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c14a2",
   "metadata": {},
   "source": [
    "Now, let's ask the agent to create a loan application \n",
    "\n",
    "You can directly pass in the string input for messages in the compiled graph, which will be converted to a `HumanMessage`. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a `SystemMessage` when passed as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = existing_mortgage_agent.invoke(\n",
    "    {\"messages\":\"I want to apply for a new mortgage. My name is John Smith, I'm 35 years old, earn $75000 annually, and have $25000 in expenses.\"\n",
    "\n",
    "}\n",
    ")\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = existing_mortgage_agent.invoke(\n",
    "    {\"messages\": \"Could you remind me what's my mortgage interest rate is?\"}\n",
    ")\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c61c4a",
   "metadata": {},
   "source": [
    "You might have noticed that the agent doesn't have any past information. Let's fix that add memory. LangGraph supports two types of memory\n",
    "- Short-term memory (thread-level memory): tracks message conversations within a single session\n",
    "- Long-term memory (cross-thread memory): stores conversations across sessions\n",
    "\n",
    "In today's lab we will be using the short-term memory. For more info you can find it [here](https://langchain-ai.github.io/langgraph/how-tos/memory/)\n",
    "\n",
    "To set up a memory and use it in the agent, we need to complete two steps:\n",
    "\n",
    "1. create memory and add it to the `graph.compile()` function\n",
    "2. supply `thread_id` in the config when invoking the agent\n",
    "\n",
    "\n",
    "Let's start with import necessary libraries , instantiate the checkpointer and assign it to the `graph.compile()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "memory = InMemorySaver()\n",
    "\n",
    "existing_mortgage_agent_with_memory = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_mortgage_details,create_customer_id,create_loan_application,get_mortgage_app_doc_status],\n",
    "    prompt=dedent(system),\n",
    "    checkpointer=memory\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859c1667",
   "metadata": {},
   "source": [
    "Now lets define the config parameter and add it the invocation. We will use random integer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": random.randint(1,10000)}}\n",
    "\n",
    "response = existing_mortgage_agent_with_memory.invoke(\n",
    "    {\"messages\":\"I want to apply for a new mortgage. My name is John Smith, I'm 35 years old, earn $75000 annually, and have $25000 in expenses.\"}\n",
    "    ,config\n",
    ")\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = existing_mortgage_agent_with_memory.invoke(\n",
    "    {\"messages\": \"Could you remind me what's my mortgage interest rate is?\"},\n",
    "    config\n",
    ") \n",
    "\n",
    "for message in response[\"messages\"][-1:]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0598d85",
   "metadata": {},
   "source": [
    "Let's add the observability piece to this setup. We use LangFuse setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load JSON config\n",
    "with open('config/langfuse.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Set environment variables from JSON\n",
    "langfuse_config = config['langfuse_server']\n",
    "os.environ['LANGFUSE_PUBLIC_KEY'] = langfuse_config['LANGFUSE_PUBLIC_KEY']\n",
    "os.environ['LANGFUSE_SECRET_KEY'] = langfuse_config['LANGFUSE_SECRET_KEY']\n",
    "os.environ['LANGFUSE_HOST'] = langfuse_config['LANGFUSE_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1de8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af77c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": random.randint(1,10000)},\"callbacks\": [langfuse_handler]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c60e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = existing_mortgage_agent_with_memory.invoke(\n",
    "    {\"messages\":\"I want to apply for a new mortgage. My name is John Smith, I'm 35 years old, earn $75000 annually, and have $25000 in expenses.\"}\n",
    "    ,config\n",
    ")\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9034cf1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated how to build a single agent using LangGraph that can handle mortgage-related queries and provide information to customers about their existing mortgages.\n",
    "\n",
    "Key components covered:\n",
    "- Basics of LangGraph\n",
    "- Creating a specialized mortgage agent with the ReAct pattern\n",
    "- Implementing  tools for retrieving mortgage details\n",
    "- Retaining memory for the agent\n",
    "\n",
    "Next, we will move on to Lab 2 where we will cover multi-agent setup, allowing different specialized agents to collaborate and handle more complex mortgage scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
